Description: Upload an object to an S3 bucket, triggering a Lambda event, returning the object key as a Stack Output.
Parameters:
  LanguageCode:
    Description: Language Code sent to Transcribe
    Type: String
    Default: zh-CN
    AllowedValues: 
      - zh-CN
      - en-US
      - en-AU
  UploadBucketName:
    Description: S3 Bucket for user uploading
    Type: String
  TargetDDBTableName:
    Description: DDB table name
    Type: String

Resources:
  SourceBucketPermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: 'lambda:InvokeFunction'
      FunctionName: !Ref FileWatcher
      Principal: s3.amazonaws.com
      SourceAccount: !Ref "AWS::AccountId"
      SourceArn: !Sub "arn:aws:s3:::${UploadBucketName}"
  
  FileWatcher:
    Type: AWS::Lambda::Function
    DependsOn: SRTGeneratorStateMachine
    Properties:
      Description: Copy source image to target bucket whilst creating record in Target DDB table
      Handler: index.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: !Sub
          - |
            import json
            import boto3
            import time
            import urllib
            import uuid
            import os
            
            s3 = boto3.client('s3')
            dynamodb = boto3.resource('dynamodb')          
            sfn = boto3.client('stepfunctions')

            def lambda_handler(event, context):
              source_bucket = event['Records'][0]['s3']['bucket']['name']
              source_key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'])              
              source_filename, source_file_extension = os.path.splitext(source_key)
              file_path, file_name = os.path.split(source_key)      
              
              userid = os.path.basename(os.path.normpath(os.path.dirname(source_key)))

              file_id = str(uuid.uuid4())

              target_ddb_table = '${TargetDDBTableName}'

              try:
                # print("Waiting for the file persist in the source bucket")
                response = s3.head_object(Bucket=source_bucket, Key=source_key)
                metadata = response['Metadata']
                waiter = s3.get_waiter('object_exists')
                waiter.wait(Bucket=source_bucket, Key=source_key)             

                # print("Putting item into DynamoDB")
                
                new_item = {
                    'id': file_id,
                    's3key': source_key,
                    'owner': userid
                  }
                
                table = dynamodb.Table(target_ddb_table)
                table.put_item(
                  Item=new_item
                )               
                response = {
                  "result": 0
                }

                # print("Starting Transcribe Job State Machine")
                sfc_event = {
                  'file_id': file_id,
                  'file_name': file_name,
                  'source_key': source_key,
                  'source_bucket': source_bucket,
                  'userid': userid
                }
                sfn_response = sfn.start_execution(
                  stateMachineArn='${SRTGeneratorStateMachine}',
                  name=file_id,
                  input=json.dumps(sfc_event)
                )

                return {
                  "statusCode": 200,
                  "body": json.dumps(response),
                }

              except Exception as e:
                print(e)
                # raise e

          - { TargetDDBTableName: !Ref TargetDDBTableName, SRTGeneratorStateMachine: !Ref SRTGeneratorStateMachine }
      Timeout: 30
      Runtime: python3.7
  
  LambdaTrigger:
    Type: 'Custom::LambdaTrigger'
    DependsOn: SourceBucketPermission
    Properties:
      ServiceToken: !GetAtt CustomResourceLambdaFunction.Arn
      LambdaArn: !GetAtt FileWatcher.Arn
      Bucket: !Ref UploadBucketName

  
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal: {Service: [lambda.amazonaws.com]}
          Action: ['sts:AssumeRole']
      Path: /
      ManagedPolicyArns:
      - "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
      Policies:
      - PolicyName: S3DDBPolicy
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
            - Effect: Allow
              Action:
                - 's3:GetObject'
                - 's3:GetObjectVersion'
              Resource: !Sub "arn:aws:s3:::${UploadBucketName}/*"
            - Effect: Allow
              Action:
                - 's3:ListBucket'
              Resource: !Sub "arn:aws:s3:::${UploadBucketName}"
            - Effect: Allow
              Action:
                - 'states:StartExecution'
              Resource: !Ref SRTGeneratorStateMachine
            - Effect: Allow
              Action:
                - 'dynamodb:PutItem'
              Resource: !Sub "arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/${TargetDDBTableName}"
            - Effect: Allow
              Action:                
                - 'dynamodb:DescribeStream'
                - 'dynamodb:GetRecords'
                - 'dynamodb:GetShardIterator'
                - 'dynamodb:ListStreams'
              Resource: "*"
  
  CustomResourceLambdaIAMRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - 'sts:AssumeRole'
          - Effect: Allow
            Principal:
              Service:
                - transcribe.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      Policies:
        - PolicyName: root
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 's3:GetBucketNotification'
                  - 's3:PutBucketNotification'
                Resource: !Sub 'arn:aws:s3:::${UploadBucketName}'
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource: 'arn:aws:logs:*:*:*'
  
  CustomResourceLambdaFunction:
    Type: 'AWS::Lambda::Function'
    Properties:
      Handler: index.lambda_handler
      Role: !GetAtt CustomResourceLambdaIAMRole.Arn
      Runtime: python3.7
      Timeout: 50
      Code:
        ZipFile: |
            from __future__ import print_function
            import json
            import boto3
            import cfnresponse
            
            SUCCESS = "SUCCESS"
            FAILED = "FAILED"
            
            print('Loading function')
            s3 = boto3.resource('s3')
            
            def lambda_handler(event, context):
                print("Received event: " + json.dumps(event, indent=2))
                responseData={}
                try:
                    if event['RequestType'] == 'Delete':
                        print("Request Type:",event['RequestType'])
                        Bucket=event['ResourceProperties']['Bucket']
                        delete_notification(Bucket)
                        print("Sending response to custom resource after Delete")
                    elif event['RequestType'] == 'Create' or event['RequestType'] == 'Update':
                        print("Request Type:",event['RequestType'])
                        LambdaArn=event['ResourceProperties']['LambdaArn']
                        Bucket=event['ResourceProperties']['Bucket']
                        add_notification(LambdaArn, Bucket)
                        responseData={'Bucket':Bucket}
                        print("Sending response to custom resource")
                    responseStatus = 'SUCCESS'
                except Exception as e:
                    print('Failed to process:', e)
                    responseStatus = 'FAILURE'
                    responseData = {'Failure': 'Something bad happened.'}
                cfnresponse.send(event, context, responseStatus, responseData)

            def add_notification(LambdaArn, Bucket):              
                bucket_notification = s3.BucketNotification(Bucket)
                response = bucket_notification.put(
                  NotificationConfiguration={
                    'LambdaFunctionConfigurations': [
                      {
                          'LambdaFunctionArn': LambdaArn,
                          'Events': [
                              's3:ObjectCreated:*'
                          ],
                          'Filter': {
                            'Key': {
                              'FilterRules': [
                                {
                                  'Name': 'prefix',
                                  'Value': 'uploads/'
                                }
                              ]
                            }
                          }
                      }
                    ]
                  }
                )
                print("Put request completed....")
              
            def delete_notification(Bucket):
                bucket_notification = s3.BucketNotification(Bucket)
                response = bucket_notification.put(
                  NotificationConfiguration={}
                )
                print("Delete request completed....")
      

  TranscribeJobStartLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Create Transcribe Job
      Handler: index.lambda_handler
      Role: !GetAtt SRTGeneratorLambdaExecutionRole.Arn
      Timeout: 30
      Runtime: python3.7
      Code:
        ZipFile: !Sub
          - |
            import json
            import boto3

            transcribe = boto3.client('transcribe')

            def lambda_handler(event, context):
              try:
                file_id = event['file_id']
                source_bucket = event['source_bucket']
                source_key=event['source_key']
                job_response = transcribe.start_transcription_job(
                  TranscriptionJobName=file_id,
                  LanguageCode='${LanguageCode}',
                  Media={
                    'MediaFileUri': 's3://%s/%s' % (source_bucket, source_key)
                  }
                )
                event["TranscriptionJobName"] = job_response['TranscriptionJob']['TranscriptionJobName']
                event["TranscriptionJobStatus"] = job_response['TranscriptionJob']['TranscriptionJobStatus']
                return event
              except Exception as e:
                print(e)
          - { LanguageCode: !Ref LanguageCode }
      

  TranscribeJobStatusLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Check Transcribe Job
      Handler: index.lambda_handler
      Role: !GetAtt SRTGeneratorLambdaExecutionRole.Arn
      Timeout: 30
      Runtime: python3.7
      Code:
        ZipFile: |
            import json
            import boto3

            transcribe = boto3.client('transcribe')

            def lambda_handler(event, context):
              try:
                job_name = event['TranscriptionJobName']
                job_response = transcribe.get_transcription_job(
                  TranscriptionJobName=job_name
                )
                event["TranscriptionJobName"] = job_response['TranscriptionJob']['TranscriptionJobName']
                event["TranscriptionJobStatus"] = job_response['TranscriptionJob']['TranscriptionJobStatus']

                if 'Transcript' in job_response['TranscriptionJob']:
                  if 'TranscriptFileUri' in job_response['TranscriptionJob']['Transcript']:
                    event['TranscriptFileUri'] = job_response['TranscriptionJob']['Transcript']['TranscriptFileUri']

                return event
              except Exception as e:
                print(e)
      
  
  SRTConversionLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Convert json file from Transcribe to SRT format
      Handler: index.handler
      Role: !GetAtt SRTGeneratorLambdaExecutionRole.Arn
      Timeout: 120
      Runtime: nodejs12.x
      Code:
        ZipFile: !Sub
          - |
              const fs = require('fs');
              const https = require('https');
              const AWS = require('aws-sdk');
              var s3 = new AWS.S3();
              class Helpers
              {
                constructor()
                {
                  const padString = (string, length) => {
                    return (new Array(length + 1).join('0') + string).slice(-length);
                  }

                  this.secondsToMinutes = (seconds) => {
                    var hours = 0;
                    var minutes = 0;
                    hours = Math.floor(seconds / 3600);
                    seconds = seconds - (hours * 3600);
                    minutes = Math.floor(seconds / 60);
                    seconds = (seconds - (minutes * 60)).toFixed(3);

                    var response = padString(hours, 2) + ':' + padString(minutes, 2) + ':' + padString(seconds, 6);
                    return response;
                  }
                }
              }
              const helpers = new Helpers();
              class SrtConvert
              {
                constructor()
                {
                }

                convertFile(file)
                {
                  let convertedOutput = '';
                  let subtitleIndex = 1;

                  const json = JSON.parse(file);
                  let current_start = json.results.items[0].start_time;
                  let formatted_start;
                  let formatted_end;
                  let nextline = '';
                  let reset = false;

                  json.results.items.map((item, index) => {
                    if (item.type == 'punctuation') {
                      nextline = nextline.slice(0, -1);
                      nextline += item.alternatives[0].content;
                      formatted_start = helpers.secondsToMinutes(current_start);
                      formatted_end = helpers.secondsToMinutes(json.results.items[index - 1].end_time);
                      convertedOutput += (subtitleIndex++) + '\n' + formatted_start + ' --> ' + formatted_end + '\n' + nextline + '\n\n';
                      nextline = '';
                      let nextItem = json.results.items[index + 1];
                      if (nextItem) {
                        current_start = json.results.items[index + 1].start_time;
                      }
                    } else if (item.end_time - current_start > 5) {
                      formatted_start = helpers.secondsToMinutes(current_start);
                      formatted_end = helpers.secondsToMinutes(json.results.items[index - 1].end_time);
                      convertedOutput += (subtitleIndex++) + '\n' + formatted_start + ' --> ' + formatted_end + '\n' + nextline + '\n\n';
                      nextline = item.alternatives[0].content + ' ';
                      current_start = item.start_time;
                    } else {
                      nextline += item.alternatives[0].content + '';
                    }
                  });

                  formatted_start = helpers.secondsToMinutes(current_start);
                  if (json.results.items[json.results.items.length - 1].type != 'punctuation') {
                    formatted_end = helpers.secondsToMinutes(json.results.items[json.results.items.length - 1].end_time);
                  } else {
                    formatted_end = helpers.secondsToMinutes(json.results.items[json.results.items.length - 2].end_time);
                  }

                  if (nextline) {
                    convertedOutput += (subtitleIndex++) + '\n' + formatted_start + ' --> ' + formatted_end + '\n' + nextline;
                  }
                  return convertedOutput;
                }
              }
              const srtConvert = new SrtConvert();
              var download = (url, dest, cb) => {
                var file = fs.createWriteStream(dest);
                var req = https.get(url, (resp) => {
                  resp.pipe(file);
                  file.on('finish', () => {
                    file.close(cb);
                  });
                }).on('error', (err) => {
                  fs.unlink(dest);
                  if (cb) cb(err.message);
                });
              };

              exports.handler = (event, context, callback) => {
                let sourcePath = "/tmp/input.json";
                let destinationPath = '/tmp/output.srt';      
                let targetBucket = '${TargetBucket}';

                let sURI = event['TranscriptFileUri'];
                let userid = event['userid'];
                let filename = event['file_name'];
                    
                download(sURI, sourcePath, () => {
                  fs.readFile(sourcePath, 'utf8', (err, file) => {
                    if (err) {
                      console.log(err);
                    }                    
                    const convertedOutput = srtConvert.convertFile(file);
                    const targetKey = 'protected/' + userid+'/' + filename + '.srt'
                    s3.putObject({
                      Bucket: targetBucket,
                      Key: targetKey,
                      Body: convertedOutput
                    }, (err, response) => {
                      if (err) {
                        console.log(err);
                        callback(err);
                      }           
                      event['s3key_srt_file'] = filename + '.srt';
                      callback(null, event);
                    })                    
                  });
                });
              }
          - { TargetBucket: !Ref UploadBucketName}  
  
  SRTUpdateDDBLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Check Transcribe Job
      Handler: index.lambda_handler
      Role: !GetAtt SRTGeneratorLambdaExecutionRole.Arn
      Timeout: 30
      Runtime: python3.7
      Code:
        ZipFile: !Sub
          - |
              import json
              import boto3

              dynamodb = boto3.client('dynamodb')

              def lambda_handler(event, context):
                target_ddb_table = '${TargetDDBTableName}'
                try:
                  dynamodb.update_item(
                    TableName=target_ddb_table,
                    Key={
                      'id': {
                        'S': event['file_id']                        
                      }
                    },
                    AttributeUpdates={
                      'srtfilekey': {
                        'Value': {
                          'S': event['s3key_srt_file']
                        }
                      }
                    }
                  )               

                  return event
                except Exception as e:
                  print(e)
          - { TargetDDBTableName: !Ref TargetDDBTableName }

  SRTGeneratorLambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal: {Service: [lambda.amazonaws.com]}
          Action: ['sts:AssumeRole']
      Path: /
      ManagedPolicyArns:
      - "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
      Policies:
      - PolicyName: S3DDBPolicy
        PolicyDocument:
          Version: '2012-10-17'
          Statement:
            - Effect: Allow
              Action:
                - 'transcribe:*'
              Resource: "*"
            - Effect: Allow
              Action:
                - 's3:PutObject'
              Resource: !Sub "arn:aws:s3:::${UploadBucketName}/protected/*"
            - Effect: Allow
              Action:
                - 's3:GetObject'
              Resource: !Sub "arn:aws:s3:::${UploadBucketName}/uploads/*"
            - Effect: Allow
              Action:
                - 'dynamodb:UpdateItem'
              Resource: !Sub "arn:aws:dynamodb:${AWS::Region}:${AWS::AccountId}:table/${TargetDDBTableName}"
  
  SRTGeneratorStateMachine:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      RoleArn: !GetAtt SRTGeneratorStateMachineRole.Arn
      DefinitionString:
        !Sub
          - |-
            {
              "StartAt": "TranscribeJobStart",
              "States": {
                "TranscribeJobStart": {
                  "Type": "Task",
                  "Resource": "${TranscribeJobStartLambdaArn}",
                  "Next": "TranscribeJobWait"
                },
                 "TranscribeJobWait": {
                  "Type": "Wait",
                  "Seconds": 30,
                  "Next": "TranscribeJobStatus"
                },
                "TranscribeJobStatus": {
                  "Type": "Task",
                  "Resource": "${TranscribeJobStatusLambdaArn}",
                  "Next": "IsTranscribeJobFinished"
                },
                "IsTranscribeJobFinished": {
                  "Type": "Choice",
                  "Default": "TranscribeJobWait",
                  "Choices": [
                    {
                      "Variable": "$.TranscriptionJobStatus",
                      "StringEquals": "FAILED",
                      "Next": "TranscribeJobFailed"
                    },
                    {
                      "Variable": "$.TranscriptionJobStatus",
                      "StringEquals": "COMPLETED",
                      "Next": "SRTConversion"
                    }
                  ]
                },
                 "TranscribeJobFailed": {
                  "Type": "Fail",
                  "Cause": "Transcribe Job failed",
                  "Error": "Transcribe Job failed"
                },
                "SRTConversion": {
                  "Type": "Task",
                  "Resource": "${SRTConversionLambdaArn}",
                  "Next": "SRTUpdateDDB"
                },
                "SRTUpdateDDB": {
                  "Type": "Task",
                  "Resource": "${SRTUpdateDDBLambdaArn}",
                  "Next": "SRTConversionEnd"
                },                
                "SRTConversionEnd": {
                  "Type": "Pass",
                  "End": true
                }
              }
            }

          - {TranscribeJobStartLambdaArn: !GetAtt TranscribeJobStartLambda.Arn, TranscribeJobStatusLambdaArn: !GetAtt TranscribeJobStatusLambda.Arn, SRTConversionLambdaArn: !GetAtt SRTConversionLambda.Arn, SRTUpdateDDBLambdaArn: !GetAtt SRTUpdateDDBLambda.Arn}

  SRTGeneratorStateMachineRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: "Allow"
            Principal:
              Service:
                - "states.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Path: "/"
      Policies:
        -
          PolicyName: "root"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action: "lambda:InvokeFunction"
                Resource:                  
                  - !GetAtt TranscribeJobStartLambda.Arn
                  - !GetAtt TranscribeJobStatusLambda.Arn                  
                  - !GetAtt SRTConversionLambda.Arn
                  - !GetAtt SRTUpdateDDBLambda.Arn

